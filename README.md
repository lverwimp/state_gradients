# State Gradients

This is code for calculating, printing and analyzing state gradients of neural language models. State gradients are the gradients of the hidden state of the network with respect to its input embedding. 

It is both a simplified version of [my other GitHub repo](https://github.com/lverwimp/tf-lm/), since it only allows you to train word-level language models, and an extension of it, since it allows you to calculate the state gradients and print them. 

See [this paper](https://www.researchgate.net/publication/325818651_State_Gradients_for_RNN_Memory_Analysis) for more information.


